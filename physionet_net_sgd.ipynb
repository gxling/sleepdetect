{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# My libraries\n",
    "import network\n",
    "import fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取睡眠标签及观察值序列文件'..\\\\HMM_train\\\\hmm_obsv.txt',转换成network标准数据格式（x,y）\n",
    "cwd = os.getcwd()\n",
    "HMM_data_path = os.path.join(cwd, 'HMM_train')\n",
    "file =  os.path.join(HMM_data_path, 'hmm_obsv.txt') \n",
    "# fid = open(file,\"r\")\n",
    "# note = fid.readlines()\n",
    "# fid.close()\n",
    "with open(file,\"r\") as fid:\n",
    "    note = fid.readlines()\n",
    "    \n",
    "tag = []\n",
    "T = 960 \n",
    "data = np.empty((len(note),T))\n",
    "i = 0\n",
    "for line in note:\n",
    "    line_new = line.split(\",\")\n",
    "    tag.append(fun.st2num(line_new[0][0]))\n",
    "    data[i] = int(line_new[1])\n",
    "    i+=1\n",
    "\n",
    "#转换成（x,y）标准数据格式network \n",
    "data_net = [d.reshape(960,1) for d in data]\n",
    "tag_net = [fun.vectorized_result(t) for t in tag]\n",
    "     \n",
    "data_tag = zip(data_net,tag_net)\n",
    "data_tag = list(data_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      " [1211 1212 1213 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [   0    1    2 ... 1208 1209 1210]\n",
      "========\n",
      "Baseline classifier using an SVM.\n",
      "361 of 1211 values correct.\n",
      "Classifier using an MLP.\n",
      "231 of 1211 values correct.\n",
      "TRAIN:\n",
      " [   0    1    2 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [1211 1212 1213 ... 2419 2420 2421]\n",
      "========\n",
      "Baseline classifier using an SVM.\n",
      "431 of 1211 values correct.\n",
      "Classifier using an MLP.\n",
      "552 of 1211 values correct.\n",
      "TRAIN:\n",
      " [   0    1    2 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [2422 2423 2424 ... 3630 3631 3632]\n",
      "========\n",
      "Baseline classifier using an SVM.\n",
      "355 of 1211 values correct.\n",
      "Classifier using an MLP.\n",
      "343 of 1211 values correct.\n",
      "TRAIN:\n",
      " [   0    1    2 ... 3630 3631 3632] \n",
      "TEST:\n",
      " [3633 3634 3635 ... 4841 4842 4843]\n",
      "========\n",
      "Baseline classifier using an SVM.\n",
      "261 of 1211 values correct.\n",
      "Classifier using an MLP.\n",
      "422 of 1211 values correct.\n"
     ]
    }
   ],
   "source": [
    "# len(data_tag)=4844\n",
    "# 使用kfold（K-交叉验证）划分训练集、测试集\n",
    "KF=KFold(n_splits=4) #建立4折交叉验证方法\n",
    "\n",
    "for train_index,test_index in KF.split(data):\n",
    "    print(\"TRAIN:\\n\",train_index,\"\\nTEST:\\n\",test_index)\n",
    "    print(\"========\")\n",
    "    #data_train,data_test=data[train_index],data_tag[test_index]#报错，改成下面两行\n",
    "    data_train = [data[index] for index in train_index]\n",
    "    data_test = [data[index] for index in test_index]\n",
    "    # 对应标签\n",
    "    tag_train = [tag[index] for index in train_index]\n",
    "    tag_test = [tag[index] for index in test_index]\n",
    "    # 转换为sk_learn 标准数据格式\n",
    "    data_train = (data_train, np.array(tag_train).reshape(len(tag_train),))\n",
    "    data_test = (data_test, np.array(tag_test).reshape(len(tag_test),))\n",
    "    \n",
    "    # 1）使用sk-learn中的svm分类，做参照\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(data_train[0], data_train[1])\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(data_test[0])]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, data_test[1]))\n",
    "    print(\"Baseline classifier using an SVM.\")\n",
    "    print(str(num_correct) + \" of \" + str(len(data_test[1])) + \" values correct.\")\n",
    "    \n",
    "    # 2）使用sk-learn中的MLPClassifier分类\n",
    "    clf = MLPClassifier(alpha=1)\n",
    "    clf.fit(data_train[0], data_train[1])\n",
    "    # test\n",
    "    predictions = [int(a) for a in clf.predict(data_test[0])]\n",
    "    num_correct = sum(int(a == y) for a, y in zip(predictions, data_test[1]))\n",
    "    print(\"Classifier using an MLP.\")\n",
    "    print(str(num_correct) + \" of \" + str(len(data_test[1])) + \" values correct.\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      " [1211 1212 1213 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [   0    1    2 ... 1208 1209 1210]\n",
      "========\n",
      "Epoch 0 : 49 / 1211\n",
      "Epoch 1 : 49 / 1211\n",
      "Epoch 2 : 536 / 1211\n",
      "Epoch 3 : 63 / 1211\n",
      "Epoch 4 : 66 / 1211\n",
      "Epoch 5 : 536 / 1211\n",
      "Epoch 6 : 536 / 1211\n",
      "Epoch 7 : 63 / 1211\n",
      "Epoch 8 : 360 / 1211\n",
      "Epoch 9 : 536 / 1211\n",
      "Epoch 10 : 536 / 1211\n",
      "Epoch 11 : 66 / 1211\n",
      "Epoch 12 : 125 / 1211\n",
      "Epoch 13 : 360 / 1211\n",
      "Epoch 14 : 516 / 1211\n",
      "Epoch 15 : 360 / 1211\n",
      "Epoch 16 : 360 / 1211\n",
      "Epoch 17 : 360 / 1211\n",
      "Epoch 18 : 152 / 1211\n",
      "Epoch 19 : 536 / 1211\n",
      "Epoch 20 : 360 / 1211\n",
      "Epoch 21 : 360 / 1211\n",
      "Epoch 22 : 360 / 1211\n",
      "Epoch 23 : 66 / 1211\n",
      "Epoch 24 : 172 / 1211\n",
      "Epoch 25 : 360 / 1211\n",
      "Epoch 26 : 172 / 1211\n",
      "Epoch 27 : 360 / 1211\n",
      "Epoch 28 : 152 / 1211\n",
      "Epoch 29 : 172 / 1211\n",
      "TRAIN:\n",
      " [   0    1    2 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [1211 1212 1213 ... 2419 2420 2421]\n",
      "========\n",
      "Epoch 0 : 101 / 1211\n",
      "Epoch 1 : 115 / 1211\n",
      "Epoch 2 : 101 / 1211\n",
      "Epoch 3 : 39 / 1211\n",
      "Epoch 4 : 39 / 1211\n",
      "Epoch 5 : 115 / 1211\n",
      "Epoch 6 : 101 / 1211\n",
      "Epoch 7 : 115 / 1211\n",
      "Epoch 8 : 39 / 1211\n",
      "Epoch 9 : 30 / 1211\n",
      "Epoch 10 : 461 / 1211\n",
      "Epoch 11 : 115 / 1211\n",
      "Epoch 12 : 101 / 1211\n",
      "Epoch 13 : 101 / 1211\n",
      "Epoch 14 : 101 / 1211\n",
      "Epoch 15 : 115 / 1211\n",
      "Epoch 16 : 115 / 1211\n",
      "Epoch 17 : 115 / 1211\n",
      "Epoch 18 : 101 / 1211\n",
      "Epoch 19 : 461 / 1211\n",
      "Epoch 20 : 101 / 1211\n",
      "Epoch 21 : 101 / 1211\n",
      "Epoch 22 : 39 / 1211\n",
      "Epoch 23 : 39 / 1211\n",
      "Epoch 24 : 39 / 1211\n",
      "Epoch 25 : 115 / 1211\n",
      "Epoch 26 : 101 / 1211\n",
      "Epoch 27 : 101 / 1211\n",
      "Epoch 28 : 115 / 1211\n",
      "Epoch 29 : 101 / 1211\n",
      "TRAIN:\n",
      " [   0    1    2 ... 4841 4842 4843] \n",
      "TEST:\n",
      " [2422 2423 2424 ... 3630 3631 3632]\n",
      "========\n",
      "Epoch 0 : 149 / 1211\n",
      "Epoch 1 : 149 / 1211\n",
      "Epoch 2 : 118 / 1211\n",
      "Epoch 3 : 149 / 1211\n",
      "Epoch 4 : 403 / 1211\n",
      "Epoch 5 : 118 / 1211\n",
      "Epoch 6 : 124 / 1211\n",
      "Epoch 7 : 118 / 1211\n",
      "Epoch 8 : 62 / 1211\n",
      "Epoch 9 : 149 / 1211\n",
      "Epoch 10 : 118 / 1211\n",
      "Epoch 11 : 149 / 1211\n",
      "Epoch 12 : 118 / 1211\n",
      "Epoch 13 : 354 / 1211\n",
      "Epoch 14 : 149 / 1211\n",
      "Epoch 15 : 118 / 1211\n",
      "Epoch 16 : 75 / 1211\n",
      "Epoch 17 : 118 / 1211\n",
      "Epoch 18 : 118 / 1211\n",
      "Epoch 19 : 118 / 1211\n",
      "Epoch 20 : 87 / 1211\n",
      "Epoch 21 : 354 / 1211\n",
      "Epoch 22 : 124 / 1211\n",
      "Epoch 23 : 124 / 1211\n",
      "Epoch 24 : 124 / 1211\n",
      "Epoch 25 : 118 / 1211\n",
      "Epoch 26 : 149 / 1211\n",
      "Epoch 27 : 372 / 1211\n",
      "Epoch 28 : 376 / 1211\n",
      "Epoch 29 : 118 / 1211\n",
      "TRAIN:\n",
      " [   0    1    2 ... 3630 3631 3632] \n",
      "TEST:\n",
      " [3633 3634 3635 ... 4841 4842 4843]\n",
      "========\n",
      "Epoch 0 : 87 / 1211\n",
      "Epoch 1 : 422 / 1211\n",
      "Epoch 2 : 100 / 1211\n",
      "Epoch 3 : 490 / 1211\n",
      "Epoch 4 : 477 / 1211\n",
      "Epoch 5 : 489 / 1211\n",
      "Epoch 6 : 99 / 1211\n",
      "Epoch 7 : 477 / 1211\n",
      "Epoch 8 : 477 / 1211\n",
      "Epoch 9 : 477 / 1211\n",
      "Epoch 10 : 489 / 1211\n",
      "Epoch 11 : 489 / 1211\n",
      "Epoch 12 : 477 / 1211\n",
      "Epoch 13 : 490 / 1211\n",
      "Epoch 14 : 99 / 1211\n",
      "Epoch 15 : 99 / 1211\n",
      "Epoch 16 : 489 / 1211\n",
      "Epoch 17 : 489 / 1211\n",
      "Epoch 18 : 489 / 1211\n",
      "Epoch 19 : 422 / 1211\n",
      "Epoch 20 : 99 / 1211\n",
      "Epoch 21 : 87 / 1211\n",
      "Epoch 22 : 99 / 1211\n",
      "Epoch 23 : 100 / 1211\n",
      "Epoch 24 : 99 / 1211\n",
      "Epoch 25 : 49 / 1211\n",
      "Epoch 26 : 99 / 1211\n",
      "Epoch 27 : 87 / 1211\n",
      "Epoch 28 : 477 / 1211\n",
      "Epoch 29 : 489 / 1211\n"
     ]
    }
   ],
   "source": [
    "# 结论：svm,hmm,network也很低，说明预处理中特征处理方式待改进，下面尝试bp-network\n",
    "net = network.Network([960, 100, 6])\n",
    "# use stochastic gradient descent to learn from the training_data over 30 epochs, \n",
    "# with a mini-batch size of 10, and a learning rate of η=3.0\n",
    "\n",
    "# len(data_tag)=4844\n",
    "# 使用kfold（K-交叉验证）划分训练集、测试集\n",
    "KF=KFold(n_splits=4) #建立4折交叉验证方法\n",
    "\n",
    "for train_index,test_index in KF.split(data_tag):\n",
    "    print(\"TRAIN:\\n\",train_index,\"\\nTEST:\\n\",test_index)\n",
    "    print(\"========\")\n",
    "\n",
    "    data_train = [data_tag[index] for index in train_index]\n",
    "    data_test = [data_tag[index] for index in test_index]\n",
    "#     print(data_test[0][1].shape)\n",
    "#     print(data_test[0][0].shape)\n",
    "#     print(len(data_test))\n",
    "    net.SGD(data_train, 30, 100, 3, test_data=data_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
